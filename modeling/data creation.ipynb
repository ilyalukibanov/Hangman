{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re \n",
    "import ipyparallel as ipp \n",
    " \n",
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/words_alpha.txt', 'r') as f: \n",
    "    data = f.read() \n",
    "words = data.splitlines() \n",
    "words = [w.strip() for w in words] # get rid of any leading or trailing white space \n",
    "words = [w for w in words if w] # get rid of any empty strings \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_combinations(n): \n",
    "    \"\"\"\n",
    "    Function to create binary masks for a given number of unique characters in a word\n",
    "    \"\"\"\n",
    "    # Loop through all numbers from 0 to 2^n - 1 \n",
    "    r = [] \n",
    "    for i in range(1 << n): \n",
    "        # Convert the current number to a binary string of length n \n",
    "        binary_str = format(i, '0' + str(n) + 'b') \n",
    "        r.append(binary_str) \n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks to extract letters from words for further data creation\n",
    "masks = {} \n",
    "negative_masks = {} \n",
    "target_masks = {} \n",
    "full_masks = {} \n",
    "for i in range(1,17): \n",
    "    mask = torch.tensor(np.array([[*s] for s in create_binary_combinations(i)[:-1]], dtype=int).astype(bool)) # need double type conversion to keep '0' -> False \n",
    "    masks[i] = mask \n",
    "    negative_masks[i] = ~mask \n",
    "    targets_mask_proxy = (negative_masks[i] * np.arange(1, i+1)).reshape(-1) \n",
    "    target_masks[i] = np.delete(targets_mask_proxy,np.where(targets_mask_proxy == 0)) - 1 \n",
    "    full_masks[i] = ~torch.repeat_interleave(mask, mask.shape[1]-mask.sum(1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b51bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = ipp.Cluster(n=n_cores) \n",
    "cluster.start_cluster_sync() \n",
    "rc = cluster.connect_client_sync() \n",
    "rc.wait_for_engines(n_cores) \n",
    "rc.block = True \n",
    "dview = rc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b47d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = \"abcdefghijklmnopqrstuvwxyz\" \n",
    "stoi = {ch:i+1 for i,ch in enumerate(chars)} \n",
    "itos = {i:s for s,i in stoi.items()} # inverse mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(letters: torch.tensor, word): \n",
    "    \"\"\"\n",
    "    Create data for a single word\n",
    "    \"\"\"\n",
    "    n_unique_letters = len(letters) \n",
    "    x_mask = full_masks[n_unique_letters] * letters \n",
    "    xs = [] \n",
    "    for row in x_mask: \n",
    "        letter_filter = ''.join([itos[l] for l in row.tolist() if l != 0]) \n",
    "        output = re.sub(f'[{letter_filter}]','_',word) \n",
    "        xs.append(output) \n",
    "    return (xs, torch.tensor(letters)[target_masks[n_unique_letters]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for each process\n",
    "word_splits = [] \n",
    "words_per_core = len(words) // n_cores \n",
    "for i in range(n_cores): \n",
    "    word_splits.append(words[i*words_per_core:(i+1)*words_per_core]) \n",
    "unfinished_words = len(words) - words_per_core*n_cores \n",
    "word_splits[-1].extend(words[-unfinished_words:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23803203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_creation_wrapper(words): \n",
    "    \"\"\"\n",
    "    Wrapper function that processes a list of words.\n",
    "    The function will be send to a process.\n",
    "    \"\"\"\n",
    "    targets = [] \n",
    "    data_new = [] \n",
    "    for _, word in enumerate(words): \n",
    "        letters = torch.tensor([stoi[e] for e in list(set(word))]) \n",
    "        if len(letters) > 0: \n",
    "            d,t = create_data(letters,word) \n",
    "            targets.append(t) \n",
    "            data_new.append(d) \n",
    "    y = torch.concatenate(targets) \n",
    "    return (data_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the data processing\n",
    "dview.execute(\"import torch\\nimport re\") \n",
    "dview.push(dict(full_masks=full_masks,target_masks=target_masks,create_data=create_data,stoi=stoi,itos=itos)) \n",
    "output = dview.map_sync(data_creation_wrapper, word_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine y data into a single tensor\n",
    "data_y = torch.concat([o[1] for o in output]) \n",
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3305885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine x data into a single list\n",
    "data_x = [a for o in output for e in o[0] for a in e] \n",
    "len(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f674d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save x list\n",
    "f = open(f'data/x.txt', 'w') \n",
    "x_data = '\\n'.join(data_x) \n",
    "f.write(x_data) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save y tensor\n",
    "torch.save(data_y,f'data/y.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
